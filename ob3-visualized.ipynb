{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OB3 CASSANDRA TABLES \n",
    "\n",
    "## OVERVIEW\n",
    "\n",
    "This report focuses on the design and use cases of three proposed tables for Oceanbrowser. The tables are categorized by their intended audiences who obviously have different data consumption needs: Ob3 owners, teachers and administrators, and students. This grouping reflects Cassandra's [query-oriented design principle] (https://cassandra.apache.org/doc/latest/data_modeling/intro.html#query-driven-modeling), which states that tables should serve some particular queries only and it's natural for data to be duplicated/denormalized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADMIN-ORIENTED TABLES\n",
    "\n",
    "## TABLE DESIGN AND DISCUSSION\n",
    "\n",
    "Here's the snapshot of the create table statement for the *component* table.\n",
    "\n",
    "![ob3.component](cassandra_tables/ob3.component.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Example: Total File Usage Across All Courses\n",
    "\n",
    "The following query can be used to get an overview of file usage across different courses. If needed, the table can also add an extra layer of grouping such as department and university."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get the Data from Cassandra\n",
    "\n",
    "Notice that Python only transforms the result into a table and visualise it into a sunburst chart, as the data is already prepared by Cassandra.  \n",
    "\n",
    "The actual query can be seen in the *string* argument passed onto the make_queries_get_df() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import make_queries_get_df\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# get data for file usage\n",
    "file_usage_df = make_queries_get_df('''\n",
    "SELECT course_id, paper_id, document_id, type, COUNT(type) as count, SUM(size) as size_in_kb\n",
    "FROM component\n",
    "GROUP BY course_id, paper_id, document_id, type;\n",
    "''')\n",
    "\n",
    "# convert 'size_in_kb' to megabyte and store the result as a new column.\n",
    "file_usage_df['size_in_mb'] = round(file_usage_df['size_in_kb']/1000, 2)\n",
    "\n",
    "file_usage_df_fig = px.sunburst(file_usage_df, \n",
    "                                path=['course_id', 'paper_id', 'document_id', 'type'], \n",
    "                                values='size_in_mb',\n",
    "                                color='size_in_mb',\n",
    "                                color_continuous_midpoint=file_usage_df['size_in_mb'].mean(),\n",
    "                                color_continuous_scale='reds',\n",
    "                                range_color=[0,60],\n",
    "                                maxdepth=2)\n",
    "\n",
    "#overwrite the default template with our own. Whatever comes between <..> are html tags for formatting. \n",
    "\n",
    "#The values are wrapped inside %{...} and come from the input above. \n",
    "\n",
    "#\"color:. 0f\" is just a way to format how many digits appear after the dot, since color is a list of numbers.\n",
    "\n",
    "file_usage_df_fig.update_traces(hovertemplate='<b>%{label}</b><br><br>File Usage: %{value} MB<br>Count: %{color: .0f}')\n",
    "\n",
    "file_usage_df_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The boldness of the color indicates how much resource a particular course or paper is consuming, and the actual stat is shown on hover along with the total count of materials.\n",
    "\n",
    "An adminstrator can also click on a slice to further investigate usage by different type of materials. Together, these stats can help inform business decisions about usage plans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd example: getting contributions by each individuals in a paper\n",
    "\n",
    "The below queries can be run to produce an instant breakdown of contributions by each student to each document in a paper. \n",
    "\n",
    "If an instructor's teaching multiple papers, similar queries can be made for each paper and they can be implemented as separate option from a drop-down menu.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Get Data as Dataframe from Cassandra\n",
    "\n",
    "The helper function *make_queries_get_df()* accepts a string of CQL statement as its argument and hides the details of connecting to Cassandra and executing CQL query using Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import make_queries_get_df\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "contribution_by_paperC1_df = make_queries_get_df('''\n",
    "SELECT paper_id, document_id, author_full_name, type, COUNT(type) as count\n",
    "FROM component\n",
    "WHERE course_id = 'courseC'\n",
    "AND paper_id = 'paperC1'\n",
    "GROUP BY document_id, type;\n",
    "''')\n",
    "\n",
    "#generate the figure object\n",
    "\n",
    "contribution_by_paperC1_df_fig = px.sunburst(contribution_by_paperC1_df,\n",
    "                                             path=['paper_id', 'document_id', 'author_full_name', 'type'],\n",
    "                                             values='count',\n",
    "                                             color='count',\n",
    "                                             color_continuous_midpoint=contribution_by_paperC1_df['count'].mean(),\n",
    "                                             range_color=[0,50],\n",
    "                                             color_continuous_scale='teal',\n",
    "                                             maxdepth=3,)\n",
    "\n",
    "contribution_by_paperC1_df_fig.update_traces(hovertemplate='<b>%{label}</b><br><br>Count: %{value}')\n",
    "contribution_by_paperC1_df_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the data's already sorted and grouped by Cassandra on the server side. This takes advantage of the design of the component table and does not force processing on the client side.\n",
    "\n",
    "Since the width of a slice is proportioned based on the number of contributions made by a student, a teacher can quickly identify those who have been relatively quiet. \n",
    "\n",
    "Since *count* is still a crude metric for measuring engagement, teachers can give different weights to different materials to generate more accurate statistics. For example, a discussion may worth more engagement point than, say, a link to an outside article."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Materialized View for Student-Centric Visualisations\n",
    "\n",
    "### Example 1: Individual Contributions\n",
    "\n",
    "Using materialized view in Cassandra, we can construct a virtual table based on the component table with an added primary key. \n",
    "\n",
    "We can also redefine which keys are the partition keys and which are the clustering keys.\n",
    "\n",
    "### Redefining the Primary Key using Materialized View\n",
    "\n",
    "Let's say we want to know the contributions of a student with id 2. We can't get an overview using the component table because its primary key uses 'course_id' and 'paper_id' as its partition key. The clustering key also begins with 'document_id', 'type' and then comes 'author_id'. \n",
    "\n",
    "This means we can only select a contributions of a student for a document, and we need to make several select statements to get an overview of all the contributions across all documents.\n",
    "\n",
    "To solve this problem, we can use materialized view to cast the 'author_id' as the partition key, and the rest of the keys as clustering columns. These allow the data to be efficiently accessed as well as pre-sorted.\n",
    "\n",
    "Here's the full CQL statement for creating the Materialized View:\n",
    "\n",
    "CREATE MATERIALIZED VIEW component_by_author_id <br>\n",
    "AS SELECT * FROM component <br>\n",
    "WHERE course_id IS NOT NULL <br>\n",
    "AND paper_id IS NOT NULL <br>\n",
    "AND document_id IS NOT NULL <br>\n",
    "AND type IS NOT NULL <br>\n",
    "AND author_id IS NOT NULL <br>\n",
    "AND time_added IS NOT NULL <br>\n",
    "PRIMARY KEY (author_id, course_id, paper_id, document_id, type, time_added);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "\n",
    "Next, we simply query the materialized view like any CQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import make_queries_get_df\n",
    "\n",
    "contributions_of_student_2_df = make_queries_get_df('''\n",
    "SELECT author_full_name, course_id, paper_id, document_id, type, count(type) as count\n",
    "FROM component_by_author_id\n",
    "WHERE author_id = '2'\n",
    "GROUP BY course_id, paper_id, document_id, type;\n",
    "''')\n",
    "\n",
    "contributions_of_student_2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data\n",
    "\n",
    "Finally, we can take advantage of Cassandra's pre-sorted result to visualise the data into a sunburst chart. \n",
    "\n",
    "Notice that only the name of the student in question appears in the center. This is because *author_full_name* is the first column and we know that it's the same thanks to the fact that *author_id* is the partition key, giving us access to all data of a student in one place. \n",
    "\n",
    "As a result, a student, in this case Rory, can quickly get an overview of what she/he has contributed in each document in a paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import make_queries_get_df\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "contributions_of_student_2_df = make_queries_get_df('''\n",
    "SELECT author_full_name, paper_id, document_id, type, count(type) as count\n",
    "FROM component_by_author_id\n",
    "WHERE author_id = '2'\n",
    "GROUP BY course_id, paper_id, document_id, type;\n",
    "''')\n",
    "\n",
    "#generate the figure object\n",
    "\n",
    "contributions_of_student_2_df_fig = px.sunburst(contributions_of_student_2_df,\n",
    "                                             path=['author_full_name', 'paper_id', 'document_id', 'type'],\n",
    "                                             values='count',\n",
    "                                             color='count',\n",
    "                                             color_continuous_midpoint=contributions_of_student_2_df['count'].mean(),\n",
    "                                             range_color=[0,20],\n",
    "                                             color_continuous_scale='teal',\n",
    "                                             maxdepth=3,)\n",
    "\n",
    "contributions_of_student_2_df_fig.update_traces(hovertemplate='<b>%{label}</b><br><br>Count: %{value}')\n",
    "contributions_of_student_2_df_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Finding Uncited Sources\n",
    "\n",
    "A student may wish to add missing references to their contributions as an academic requirement and good practice. It would be handy to get a report of which of their contributions need citation and where they can be found.\n",
    "\n",
    "Our current *component* table does not support direct filtering on 'source', but a materialized view can take an extra primary key and this is a good use case.\n",
    "\n",
    "Ideally, the table should return all contributions whose 'source' is missing from a user_id. The result should also contain the whereabouts of them so that a user/student can quickly navigate.\n",
    "\n",
    "### Create a materialized view with *source* as primary key\n",
    "\n",
    "Here's the CQL statement.\n",
    "\n",
    "// create a materialized view for identifying missing source\n",
    "\n",
    "CREATE MATERIALIZED VIEW component_source_by_author_id AS SELECT * FROM component <br>\n",
    "WHERE course_id IS NOT NULL <br>\n",
    "AND paper_id IS NOT NULL <br>\n",
    "AND document_id IS NOT NULL <br>\n",
    "AND type IS NOT NULL <br>\n",
    "AND author_id IS NOT NULL <br>\n",
    "AND time_added IS NOT NULL <br>\n",
    "AND source IS NOT NULL <br> <small>(the extra primary key)</small><br>\n",
    "PRIMARY KEY (author_id, source, course_id, paper_id, document_id, type, time_added);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the order of the new primary key. Since we imagine that a user may want to know a list uncited contributions, we map the query to the order of the primary key components. \n",
    "\n",
    "This design also illustrates how Cassandra tables should be conceived, as what comes after, not before the queries.\n",
    "\n",
    "### The Code\n",
    "\n",
    "Similar to other examples, we first extract the data, and then visualise it with an appropriate visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queries import make_queries_get_df\n",
    "\n",
    "\n",
    "uncited_contributions_of_Tom = make_queries_get_df('''\n",
    "SELECT document_id, type, source as status, time_added\n",
    "FROM component_source_by_author_id\n",
    "WHERE author_id = '8'\n",
    "AND source = 'missing'\n",
    "GROUP BY course_id, paper_id, document_id;\n",
    "''')\n",
    "\n",
    "uncited_contributions_of_Tom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result looks promising (or rather frustrating for Tom), but it doesn't allow him to jump inside a document to fix things. This is because our test table does not contain an actual *document_id* or *component_id* (substituted by *time_added*). \n",
    "\n",
    "These ids can in turn serve as breadcrumbs as there could be a table that records the location of a component by its id (like a URL). We can also include this attribute inside our *component* table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NAVIGATION QUERIES\n",
    "\n",
    "As of the momement, the ob3 platform could greatly improve the experience of users alike by adding navigation breadcrumbs of various forms to their client side. The following tables are some suggestions toward that goal, with a focus on students as users.\n",
    "\n",
    "## Bookmarked, Favorite, and Annotated Components\n",
    "\n",
    "Instead of searching through each document in each paper for marked materials, students should be able to easily locate their desired materials through a sidebar tab showing the list of all of their bookmarks, favorites, and notes, plus links to these places. \n",
    "\n",
    "This means there should be a table containing such information for each student, and the list should be sorted by document and paper. In CQL terms, our create table statement could look something like this:\n",
    "\n",
    "CREATE TABLE marked_component_by_user_id ( <br>\n",
    "    user_id TEXT,  <br>\n",
    "    paper_id TEXT,  <br>\n",
    "    doc_id TEXT,  <br>\n",
    "    bookmarked map<timeuuid, text>,  <br>\n",
    "    favorite map<timeuuid, text>,  <br>\n",
    "    annotated map<timeuuid, text>,  <br>\n",
    "    PRIMARY KEY ((user_id, paper_id),  <br>\n",
    "    doc_id));  <br>\n",
    "\n",
    "Using Cassandra built-in collection type map, we can store a map where for each element, the key is the component id and the value is the link to it. There should also be three separate maps for each type of interaction.\n",
    "\n",
    "Note that when updating the table, we should use CQL's *UPDATE ... SET ... field = field +/- element key + value* instead of *INSERT INTO ... VALUES*, since the latter would replace the old map with a new one. The first, however, simply append or remove an element from the map.  \n",
    "\n",
    "Let's look at the result from such a table for user_id = '2' who's interested in checking out all the components that they have interacted with in a paper, grouped by document.\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we're getting Cassandra's map type as result, we need to import some special function that helps with processing the result into a dataframe.\n",
    "\n",
    "from cloud import session\n",
    "from pandas_factory import pandas_factory\n",
    "session.row_factory = pandas_factory\n",
    "\n",
    "query = '''\n",
    "SELECT doc_id, bookmarked, favorite, annotated \n",
    "FROM marked_component_by_user_id\n",
    "WHERE user_id = '2' \n",
    "AND paper_id = 'paperB' \n",
    "GROUP BY doc_id;\n",
    "'''\n",
    "\n",
    "result = session.execute(query, timeout=None)\n",
    "marked_component_of_user_2_df = result._current_rows\n",
    "\n",
    "marked_component_of_user_2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that in production the key of each entry in each dictionary will be the id of the component that was marked by the user, and the URL will be the actual URL leading to the component itself. \n",
    "\n",
    "Since *doc_id* is also one of the clustering key, we can filter the result by a document name in case the user wants to get these items within a document rather than a paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cloud import session\n",
    "from pandas_factory import pandas_factory\n",
    "session.row_factory = pandas_factory\n",
    "\n",
    "query = '''\n",
    "SELECT doc_id, bookmarked, favorite, annotated \n",
    "FROM marked_component_by_user_id\n",
    "WHERE user_id = '2' \n",
    "AND paper_id = 'paperB' \n",
    "AND doc_id = 'docB1';\n",
    "'''\n",
    "\n",
    "result = session.execute(query, timeout=None)\n",
    "marked_component_of_user_2_in_docB1_df = result._current_rows\n",
    "\n",
    "marked_component_of_user_2_in_docB1_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "language": "python",
   "name": "python38364bit2021e240fa0b450c871765cfc61481f0",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}